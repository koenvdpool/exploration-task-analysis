{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mann-Whitney U test: Compare Human Performance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ba27a7bef53883b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import pandas as pd\n",
    "from scripts.utils import rank_biserial"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T12:49:48.978628Z",
     "start_time": "2024-06-06T12:49:48.974998Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare: Human"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4655b1667636a341"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df_6hum = pd.read_csv('../csv_data/nonsem_6hum.csv')\n",
    "df_1bot_5hum = pd.read_csv('../csv_data/nonsem_1bot_5hum.csv')\n",
    "df_3bots_3hum = pd.read_csv('../csv_data/nonsem_3bots_3hum.csv')\n",
    "\n",
    "# Extract the 'ItemsFound' column when isRobot == 0\n",
    "items_found_6hum = df_6hum['ItemsFound']\n",
    "items_found_5hum = df_1bot_5hum[df_1bot_5hum['isRobot'] == 0]['ItemsFound']\n",
    "items_found_3hum = df_3bots_3hum[df_3bots_3hum['isRobot'] == 0]['ItemsFound']\n",
    "\n",
    "# Extract the 'Score' column when isRobot == 0\n",
    "score_6hum = df_6hum['Score']\n",
    "score_5hum = df_1bot_5hum[df_1bot_5hum['isRobot'] == 0]['Score']\n",
    "score_3hum = df_3bots_3hum[df_3bots_3hum['isRobot'] == 0]['Score']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T13:27:09.286032Z",
     "start_time": "2024-06-06T13:27:09.276757Z"
    }
   },
   "id": "ab4cb4754ced23ae",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compare Items: 3 bots, 3 humans vs 6 humans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c89f4666a709f6f3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items 3 humans vs 6 humans: U-statistic = 24852.5, p-value = 0.003222376146221037, Rank-Biserial = 0.1714036576168929\n",
      "Score 3 humans vs 6 humans: U-statistic = 25482.0, p-value = 0.0007013835340530483, Rank-Biserial = 0.20107466063348411\n"
     ]
    }
   ],
   "source": [
    "# Perform Mann-Whitney U test (alternative='greater') for the 'ItemsFound' column\n",
    "stat_items_3hum_vs_6hum, p_items_3hum_vs_6hum = mannwhitneyu(items_found_3hum, items_found_6hum, alternative='greater')\n",
    "r_items_3hum_vs_6hum = rank_biserial(items_found_3hum, items_found_6hum, alternative='greater')\n",
    "print(f\"Items 3 humans vs 6 humans: U-statistic = {stat_items_3hum_vs_6hum}, p-value = {p_items_3hum_vs_6hum}, Rank-Biserial = {r_items_3hum_vs_6hum}\")\n",
    "\n",
    "# Perform Mann-Whitney U test (alternative='greater') for the 'Score' column\n",
    "stat_score_3hum_vs_6hum, p_score_3hum_vs_6hum = mannwhitneyu(score_3hum, score_6hum, alternative='greater')\n",
    "r_score_3hum_vs_6hum = rank_biserial(score_3hum, score_6hum, alternative='greater')\n",
    "print(f\"Score 3 humans vs 6 humans: U-statistic = {stat_score_3hum_vs_6hum}, p-value = {p_score_3hum_vs_6hum}, Rank-Biserial = {r_score_3hum_vs_6hum}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T13:27:10.670887Z",
     "start_time": "2024-06-06T13:27:10.660167Z"
    }
   },
   "id": "97eaab18b1dd6e8d",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compare Items: 1 bot, 5 humans vs 6 humans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6e8c8161d829551"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items 5 humans vs 6 humans: U-statistic = 21269.5, p-value = 0.4841789174358023, Rank-Biserial = 0.0025216817496229726\n",
      "Score 5 humans vs 6 humans: U-statistic = 21406.5, p-value = 0.44348487126613423, Rank-Biserial = 0.008979072398189958\n"
     ]
    }
   ],
   "source": [
    "# Perform Mann-Whitney U test (alternative='greater') for the 'ItemsFound' column\n",
    "stat_items_5hum_vs_6hum, p_items_5hum_vs_6hum = mannwhitneyu(items_found_5hum, items_found_6hum, alternative='greater')\n",
    "r_items_5hum_vs_6hum = rank_biserial(items_found_5hum, items_found_6hum, alternative='greater')\n",
    "print(f\"Items 5 humans vs 6 humans: U-statistic = {stat_items_5hum_vs_6hum}, p-value = {p_items_5hum_vs_6hum}, Rank-Biserial = {r_items_5hum_vs_6hum}\")\n",
    "\n",
    "# Perform Mann-Whitney U test (alternative='greater') for the 'Score' column\n",
    "stat_score_5hum_vs_6hum, p_score_5hum_vs_6hum = mannwhitneyu(score_5hum, score_6hum, alternative='greater')\n",
    "r_score_5hum_vs_6hum = rank_biserial(score_5hum, score_6hum, alternative='greater')\n",
    "print(f\"Score 5 humans vs 6 humans: U-statistic = {stat_score_5hum_vs_6hum}, p-value = {p_score_5hum_vs_6hum}, Rank-Biserial = {r_score_5hum_vs_6hum}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T13:28:16.364852Z",
     "start_time": "2024-06-06T13:28:16.353215Z"
    }
   },
   "id": "5f80388a443dc47",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compare: 3 bots, 3 humans vs 1 bot, 5 humans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d89cf42bea0da2f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items 3 humans vs 5 humans: U-statistic = 6301.5, p-value = 0.01892902210684083, Rank-Biserial = 0.16521819526627213\n",
      "Score 3 humans vs 5 humans: U-statistic = 6382.0, p-value = 0.011818739015513058, Rank-Biserial = 0.1801035502958579\n"
     ]
    }
   ],
   "source": [
    "# Perform Mann-Whitney U test (alternative='greater') for the 'ItemsFound' column\n",
    "stat_items_3hum_vs_5hum, p_items_3hum_vs_5hum = mannwhitneyu(items_found_3hum, items_found_5hum, alternative='greater')\n",
    "r_items_3hum_vs_5hum = rank_biserial(items_found_3hum, items_found_5hum, alternative='greater')\n",
    "print(f\"Items 3 humans vs 5 humans: U-statistic = {stat_items_3hum_vs_5hum}, p-value = {p_items_3hum_vs_5hum}, Rank-Biserial = {r_items_3hum_vs_5hum}\")\n",
    "\n",
    "# Perform Mann-Whitney U test (alternative='greater') for the 'Score' column\n",
    "stat_score_3hum_vs_5hum, p_score_3hum_vs_5hum = mannwhitneyu(score_3hum, score_5hum, alternative='greater')\n",
    "r_score_3hum_vs_5hum = rank_biserial(score_3hum, score_5hum, alternative='greater')\n",
    "print(f\"Score 3 humans vs 5 humans: U-statistic = {stat_score_3hum_vs_5hum}, p-value = {p_score_3hum_vs_5hum}, Rank-Biserial = {r_score_3hum_vs_5hum}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T13:29:49.933526Z",
     "start_time": "2024-06-06T13:29:49.925051Z"
    }
   },
   "id": "3c25de1a5e9bb109",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f58be58f5bbf4ea6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
